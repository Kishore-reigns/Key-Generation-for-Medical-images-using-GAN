{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HttpRNyPAzv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kPxEIwVdPE6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# kishresun2016@gmail.com -> /content/drive/MyDrive/Sem6/CIP_Team6_2025/Transformation_zip.zip\n",
        "# kishreigns@gamil.com -> /content/drive/MyDrive/Transformation_zip.zip\n",
        "# malarvannanm11@gmail.com -> /content/drive/MyDrive/Transformation_zip.zip\n",
        "zip_path = \"/content/drive/MyDrive/CIP/Transformation.zip\"  # Change to your uploaded zip file name\n",
        "extract_path = \"/content/transformation\"\n",
        "drive_checkpoint_link = \"/content/checkpoints/deepkeygen_checkpoint.pth\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Extracted dataset at: {extract_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCWEsZLYPTQQ",
        "outputId": "729f4275-e195-4cfc-f769-41427f15071b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted dataset at: /content/transformation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torchvision import transforms, datasets, utils\n",
        "import os\n",
        "import kagglehub\n",
        "import torch.autograd as autograd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "\n",
        "data = []\n",
        "drive_checkpoint_link = \"/content/checkpoints/deepkeygen_checkpoint.pth\"\n",
        "# /checkpoints/deepkeygen_checkpoint.pth\n",
        "\n",
        "# Function to download multiple datasets\n",
        "def download_datasets(dataset_list):\n",
        "    dataset_dirs = [kagglehub.dataset_download(dataset) for dataset in dataset_list]\n",
        "    return dataset_dirs\n",
        "\n",
        "# Function to load multiple datasets into a single DataLoader\n",
        "def load_multiple_datasets(data_dirs, transform, batch_size):\n",
        "    datasets_list = [datasets.ImageFolder(data_dir, transform=transform) for data_dir in data_dirs]\n",
        "    combined_dataset = ConcatDataset(datasets_list)\n",
        "    return DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "def save_checkpoint(generator, critic, optimizer_g, optimizer_d, epoch, filepath=drive_checkpoint_link):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'generator_state_dict': generator.state_dict(),\n",
        "        'critic_state_dict': critic.state_dict(),\n",
        "        'optimizer_g_state_dict': optimizer_g.state_dict(),\n",
        "        'optimizer_d_state_dict': optimizer_d.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, filepath)\n",
        "    print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
        "\n",
        "def load_checkpoint(generator, critic, optimizer_g, optimizer_d, filepath=drive_checkpoint_link, device=None):\n",
        "    if os.path.exists(filepath) and os.path.getsize(filepath) > 0: # Check if file exists and has content\n",
        "        try:\n",
        "            checkpoint = torch.load(filepath, map_location=device)\n",
        "            generator.load_state_dict(checkpoint['generator_state_dict'])\n",
        "            critic.load_state_dict(checkpoint['critic_state_dict'])\n",
        "            optimizer_g.load_state_dict(checkpoint['optimizer_g_state_dict'])\n",
        "            optimizer_d.load_state_dict(checkpoint['optimizer_d_state_dict'])\n",
        "            start_epoch = checkpoint['epoch'] + 1\n",
        "            print(f\"Resuming training from epoch {start_epoch}\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error loading checkpoint: {e}\") # Print error message if loading fails\n",
        "            start_epoch = 0 # Start from epoch 0 if loading fails\n",
        "            print(\"Starting training from scratch due to checkpoint loading error.\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        print(\"No checkpoint found, starting training from scratch.\")\n",
        "\n",
        "    return start_epoch\n",
        "\n",
        "\n",
        "# Generator network\n",
        "# Generator network (modified to output 256x256)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),  # (512, 4, 4)\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # (256, 8, 8)\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # (128, 16, 16)\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),  # (64, 32, 32)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),  # (32, 64, 64)\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(32, 16, 4, 2, 1, bias=False),  # (16, 128, 128)\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(16, 3, 4, 2, 1, bias=False),  # (3, 256, 256)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "\n",
        "# Critic network\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 1, 4, 1, 0, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img).view(-1)\n",
        "\n",
        "# Compute gradient penalty\n",
        "def compute_gradient_penalty(critic, real_samples, fake_samples, device):\n",
        "    batch_size = real_samples.size(0)\n",
        "\n",
        "    # Ensure alpha has the same shape as real_samples\n",
        "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
        "    alpha = alpha.expand(real_samples.shape)\n",
        "\n",
        "    #print(f\"alpha shape: {alpha.shape}\")\n",
        "    #print(f\"real_samples shape: {real_samples.shape}\")\n",
        "    #print(f\"fake_samples shape: {fake_samples.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "    fake_samples = F.interpolate(fake_samples, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "\n",
        "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
        "    critic_interpolates = critic(interpolates)\n",
        "    grad_outputs = torch.ones_like(critic_interpolates, device=device)\n",
        "\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=critic_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=grad_outputs,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "\n",
        "    gradients = gradients.view(batch_size, -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "\n",
        "    return gradient_penalty\n",
        "\n",
        "\n",
        "# Save generated images\n",
        "#def save_generated_images(generator, epoch, device, num_images=8):\n",
        " #   generator.eval()\n",
        "  #  with torch.no_grad():\n",
        "   #     z = torch.randn(num_images, 100, 1, 1, device=device)\n",
        "    #    fake_images = generator(z)\n",
        "\n",
        "        # Ensure images are exactly 256x256\n",
        "     #   fake_images = F.interpolate(fake_images, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "      #  fake_images = (fake_images + 1) / 2  # Normalize from [-1,1] to [0,1]\n",
        "       # os.makedirs(\"generated_images\", exist_ok=True)\n",
        "        #image_path = f\"generated_images/epoch_{epoch}.png\"\n",
        "        #utils.save_image(fake_images, image_path, normalize=True, nrow=4)\n",
        "        #print(f\"Saved generated images at {image_path}\")\n",
        "    #generator.train()\n",
        "\n",
        "\n",
        "def save_generated_images(generator, epoch, device):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(1, 100, 1, 1, device=device)\n",
        "        fake_img = generator(z).squeeze(0)  # Shape: (3, 256, 256)\n",
        "        os.makedirs(\"generated_images\", exist_ok=True)\n",
        "        image_path = f\"generated_images/epoch_{epoch}.png\"\n",
        "        # Save image with correct size\n",
        "        utils.save_image(fake_img, image_path, normalize=True)\n",
        "\n",
        "    generator.train()\n",
        "\n",
        "\n",
        "\n",
        "# Checkpoint and loss validation in the training loop:\n",
        "def train_deepkeygen(generator, critic, source_loader, transform_loader, num_epochs, lr, device):\n",
        "    optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "    optimizer_d = optim.Adam(critic.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "    lambda_gp = 10\n",
        "    critic_iterations = 5\n",
        "\n",
        "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "    start_epoch = load_checkpoint(generator, critic, optimizer_g, optimizer_d)\n",
        "\n",
        "    csv_path = \"metrics.csv\"\n",
        "    if not os.path.exists(csv_path):\n",
        "        with open(csv_path, \"w\", newline=\"\") as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Epoch\", \"Generator Loss\", \"Critic Loss\", \"Wasserstein Distance\", \"Gradient Penalty\", \"D_real\", \"D_fake\"])\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(f\"Epoch : {epoch+1}/{num_epochs}\", flush=True)\n",
        "\n",
        "        for (source_imgs, _), (transform_imgs, _) in zip(source_loader, transform_loader):\n",
        "\n",
        "            min_batch_size = min(source_imgs.size(0), transform_imgs.size(0))\n",
        "            source_imgs = source_imgs[:min_batch_size].to(device)\n",
        "            transform_imgs = transform_imgs[:min_batch_size].to(device)\n",
        "\n",
        "            for _ in range(critic_iterations):\n",
        "                with torch.no_grad():  # Prevent gradient tracking\n",
        "                    z = torch.randn(min_batch_size, 100, 1, 1, device=device)\n",
        "                    fake_imgs = generator(z).detach()  # No gradient needed here\n",
        "\n",
        "                real_loss = critic(transform_imgs).mean()\n",
        "                fake_loss = critic(fake_imgs).mean()\n",
        "                gp = compute_gradient_penalty(critic, transform_imgs, fake_imgs, device)\n",
        "                critic_loss = fake_loss - real_loss + lambda_gp * gp\n",
        "\n",
        "                optimizer_d.zero_grad()\n",
        "                if torch.isnan(critic_loss) or torch.isinf(critic_loss):\n",
        "                    continue\n",
        "                critic_loss.backward()\n",
        "                xm.optimizer_step(optimizer_d)\n",
        "                xm.mark_step()\n",
        "\n",
        "            z = torch.randn(min_batch_size, 100, 1, 1, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "            generator_loss = -critic(fake_imgs).mean()\n",
        "\n",
        "            optimizer_g.zero_grad()\n",
        "            if torch.isnan(generator_loss) or torch.isinf(generator_loss):\n",
        "                continue\n",
        "            generator_loss.backward()\n",
        "            xm.optimizer_step(optimizer_g)\n",
        "            xm.mark_step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss D: {critic_loss.item()}, Loss G: {generator_loss.item()}\", flush=True)\n",
        "\n",
        "        wasserstein_distance = real_loss.item() - fake_loss.item()\n",
        "\n",
        "        with open(csv_path, \"a\", newline=\"\") as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([epoch+1, generator_loss.item(), critic_loss.item(), wasserstein_distance, gp.item(), real_loss.item(), fake_loss.item()])\n",
        "\n",
        "        save_generated_images(generator, epoch + 1, device)\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            save_checkpoint(generator, critic, optimizer_g, optimizer_d, epoch)\n",
        "\n",
        "    print(\"[+] Training ended\", flush=True)\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"[+] Current working directory: {os.getcwd()}\")\n",
        "\n",
        "    device = xm.xla_device()  # Use TPU device\n",
        "    #device = torch.device(\"cuda\")\n",
        "    print(f\"[+] Using device: {device}\")\n",
        "\n",
        "    #csvpath = \"/content/loss.csv\"\n",
        "\n",
        "    source_datasets = [\"raddar/tuberculosis-chest-xrays-montgomery\", \"masoudnickparvar/brain-tumor-mri-dataset\"]\n",
        "    source_data_dirs = download_datasets(source_datasets)\n",
        "\n",
        "\n",
        "    print(\"[+] Datasets downloaded successfully\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    batch_size = 32\n",
        "    num_epochs = 100\n",
        "    lr = 0.0002\n",
        "    extract_path = \"/content/transformation\"\n",
        "\n",
        "    source_loader = load_multiple_datasets(source_data_dirs, transform, batch_size)\n",
        "    transform_loader = DataLoader(datasets.ImageFolder(extract_path, transform=transform), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    print(\"[+] Datasets loaded successfully\")\n",
        "\n",
        "    generator = Generator().to(device)\n",
        "    critic = Critic().to(device)\n",
        "\n",
        "    print(\"[+] Training begins\")\n",
        "    train_deepkeygen(generator, critic, source_loader, transform_loader, num_epochs, lr, device)\n",
        "    print(\"[+] Training ended\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "W1Ouu4otPYQR",
        "outputId": "17020451-8163-40e7-d88f-dda6a5ad2330"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.11/dist-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops9from_file4callEN3c1017basic_string_viewIcEESt8optionalIbES5_IlES5_INS2_10ScalarTypeEES5_INS2_6LayoutEES5_INS2_6DeviceEES6_'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Current working directory: /content\n",
            "[+] Using device: xla:0\n",
            "[+] Datasets downloaded successfully\n",
            "[+] Datasets loaded successfully\n",
            "[+] Training begins\n",
            "Resuming training from epoch 30\n",
            "Epoch : 31/100\n",
            "Epoch [31/100], Loss D: 0.03354161977767944, Loss G: 0.0998036339879036\n",
            "Epoch : 32/100\n",
            "Epoch [32/100], Loss D: 0.751157820224762, Loss G: 0.03132796287536621\n",
            "Epoch : 33/100\n",
            "Epoch [33/100], Loss D: 0.8057565093040466, Loss G: 0.025828892365098\n",
            "Epoch : 34/100\n",
            "Epoch [34/100], Loss D: 0.062412697821855545, Loss G: 0.054898615926504135\n",
            "Epoch : 35/100\n",
            "Epoch [35/100], Loss D: 0.015147276222705841, Loss G: 0.05659060552716255\n",
            "Checkpoint saved at epoch 35\n",
            "Epoch : 36/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6e33bdd35399>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[+] Training begins\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mtrain_deepkeygen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[+] Training ended\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6e33bdd35399>\u001b[0m in \u001b[0;36mtrain_deepkeygen\u001b[0;34m(generator, critic, source_loader, transform_loader, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0moptimizer_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torch-xla\n",
        "!pip install torch\n",
        "!pip install torch-xla"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U43rzaEjPabJ",
        "outputId": "4e9aac6f-aee0-476b-dbe6-549e9229c5f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0\n",
            "Uninstalling torch-2.6.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/torchfrtrace\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.11/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch-2.6.0.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/uninstall.py\", line 106, in run\n",
            "    uninstall_pathset = req.uninstall(\n",
            "                        ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 722, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_uninstall.py\", line 364, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_uninstall.py\", line 404, in _allowed_to_proceed\n",
            "    return ask(\"Proceed (Y/n)? \", (\"y\", \"n\", \"\")) != \"n\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/misc.py\", line 235, in ask\n",
            "    response = input(message)\n",
            "               ^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1526, in critical\n",
            "    def critical(self, msg, *args, **kwargs):\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting torch-xla\n",
            "  Using cached torch_xla-2.6.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torch-xla) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-xla) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from torch-xla) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-xla) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-xla) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-xla) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-xla) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-xla) (2025.1.31)\n",
            "Downloading torch_xla-2.6.0-cp311-cp311-manylinux_2_28_x86_64.whl (93.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-xla\n",
            "Successfully installed torch-xla-2.6.0\n"
          ]
        }
      ]
    }
  ]
}