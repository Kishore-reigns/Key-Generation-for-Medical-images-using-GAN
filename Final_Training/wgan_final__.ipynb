{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"uGeU5FtFLecC","outputId":"31273a85-baa3-49cb-c552-c0ea851c1153","executionInfo":{"status":"error","timestamp":1741081556783,"user_tz":-330,"elapsed":33,"user":{"displayName":"Kalai Dharun","userId":"03087325867341907797"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Transformation_zip.zip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-49145933ff28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdrive_checkpoint_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/checkpoints/deepkeygen_checkpoint.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Transformation_zip.zip'"]}],"source":["import zipfile\n","import os\n","\n","# kishresun2016@gmail.com -> /content/drive/MyDrive/Sem6/CIP_Team6_2025/Transformation_zip.zip\n","# kishreigns@gamil.com -> /content/drive/MyDrive/Transformation_zip.zip\n","# malarvannanm11@gmail.com -> /content/drive/MyDrive/Transformation_zip.zip\n","zip_path = \"/content/drive/MyDrive/Transformation_zip.zip\"  # Change to your uploaded zip file name\n","extract_path = \"/content/transformation\"\n","drive_checkpoint_link = \"/content/drive/MyDrive/checkpoints/deepkeygen_checkpoint.pth\"\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(f\"Extracted dataset at: {extract_path}\")"]},{"cell_type":"markdown","source":[],"metadata":{"id":"svFs6ZjmeT1H"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"p0QNvzKoLikH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741082212542,"user_tz":-330,"elapsed":1901,"user":{"displayName":"Kalai Dharun","userId":"03087325867341907797"}},"outputId":"bb594a83-c862-4c88-da1a-d7f6f80fa341"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.parallel_loader as pl\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, ConcatDataset\n","from torchvision import transforms, datasets, utils\n","import os\n","import kagglehub\n","import torch.autograd as autograd\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import torch.nn.functional as F\n","import csv\n","\n","data = []\n","drive_checkpoint_link = \"/content/drive/MyDrive/checkpoints/deepkeygen_checkpoint.pth\"\n","# /checkpoints/deepkeygen_checkpoint.pth\n","\n","# Function to download multiple datasets\n","def download_datasets(dataset_list):\n","    dataset_dirs = [kagglehub.dataset_download(dataset) for dataset in dataset_list]\n","    return dataset_dirs\n","\n","# Function to load multiple datasets into a single DataLoader\n","def load_multiple_datasets(data_dirs, transform, batch_size):\n","    datasets_list = [datasets.ImageFolder(data_dir, transform=transform) for data_dir in data_dirs]\n","    combined_dataset = ConcatDataset(datasets_list)\n","    return DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n","\n","def save_checkpoint(generator, critic, optimizer_g, optimizer_d, epoch, filepath=drive_checkpoint_link):\n","    checkpoint = {\n","        'epoch': epoch,\n","        'generator_state_dict': generator.state_dict(),\n","        'critic_state_dict': critic.state_dict(),\n","        'optimizer_g_state_dict': optimizer_g.state_dict(),\n","        'optimizer_d_state_dict': optimizer_d.state_dict()\n","    }\n","    torch.save(checkpoint, filepath)\n","    print(f\"Checkpoint saved at epoch {epoch+1}\")\n","\n","def load_checkpoint(generator, critic, optimizer_g, optimizer_d, filepath=drive_checkpoint_link, device=None):\n","    if os.path.exists(filepath) and os.path.getsize(filepath) > 0: # Check if file exists and has content\n","        try:\n","            checkpoint = torch.load(filepath, map_location=device)\n","            generator.load_state_dict(checkpoint['generator_state_dict'])\n","            critic.load_state_dict(checkpoint['critic_state_dict'])\n","            optimizer_g.load_state_dict(checkpoint['optimizer_g_state_dict'])\n","            optimizer_d.load_state_dict(checkpoint['optimizer_d_state_dict'])\n","            start_epoch = checkpoint['epoch'] + 1\n","            print(f\"Resuming training from epoch {start_epoch}\")\n","        except RuntimeError as e:\n","            print(f\"Error loading checkpoint: {e}\") # Print error message if loading fails\n","            start_epoch = 0 # Start from epoch 0 if loading fails\n","            print(\"Starting training from scratch due to checkpoint loading error.\")\n","    else:\n","        start_epoch = 0\n","        print(\"No checkpoint found, starting training from scratch.\")\n","\n","    return start_epoch\n","\n","\n","# Generator network\n","# Generator network (modified to output 256x256)\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),  # (512, 4, 4)\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # (256, 8, 8)\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # (128, 16, 16)\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),  # (64, 32, 32)\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),  # (32, 64, 64)\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(32, 16, 4, 2, 1, bias=False),  # (16, 128, 128)\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(16, 3, 4, 2, 1, bias=False),  # (3, 256, 256)\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        return self.model(z)\n","\n","\n","# Critic network\n","class Critic(nn.Module):\n","    def __init__(self):\n","        super(Critic, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(128, 1, 4, 1, 0, bias=False)\n","        )\n","\n","    def forward(self, img):\n","        return self.model(img).view(-1)\n","\n","# Compute gradient penalty\n","def compute_gradient_penalty(critic, real_samples, fake_samples, device):\n","    batch_size = real_samples.size(0)\n","\n","    # Ensure alpha has the same shape as real_samples\n","    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n","    alpha = alpha.expand(real_samples.shape)\n","\n","    #print(f\"alpha shape: {alpha.shape}\")\n","    #print(f\"real_samples shape: {real_samples.shape}\")\n","    #print(f\"fake_samples shape: {fake_samples.shape}\")\n","\n","\n","\n","    fake_samples = F.interpolate(fake_samples, size=(256, 256), mode='bilinear', align_corners=False)\n","\n","\n","    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n","    critic_interpolates = critic(interpolates)\n","    grad_outputs = torch.ones_like(critic_interpolates, device=device)\n","\n","    gradients = torch.autograd.grad(\n","        outputs=critic_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=grad_outputs,\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True\n","    )[0]\n","\n","    gradients = gradients.view(batch_size, -1)\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","\n","    return gradient_penalty\n","\n","\n","# Save generated images\n","#def save_generated_images(generator, epoch, device, num_images=8):\n"," #   generator.eval()\n","  #  with torch.no_grad():\n","   #     z = torch.randn(num_images, 100, 1, 1, device=device)\n","    #    fake_images = generator(z)\n","\n","        # Ensure images are exactly 256x256\n","     #   fake_images = F.interpolate(fake_images, size=(256, 256), mode='bilinear', align_corners=False)\n","\n","      #  fake_images = (fake_images + 1) / 2  # Normalize from [-1,1] to [0,1]\n","       # os.makedirs(\"generated_images\", exist_ok=True)\n","        #image_path = f\"generated_images/epoch_{epoch}.png\"\n","        #utils.save_image(fake_images, image_path, normalize=True, nrow=4)\n","        #print(f\"Saved generated images at {image_path}\")\n","    #generator.train()\n","\n","\n","def save_generated_images(generator, epoch, device):\n","    generator.eval()\n","    with torch.no_grad():\n","        z = torch.randn(1, 100, 1, 1, device=device)\n","        fake_img = generator(z).squeeze(0)  # Shape: (3, 256, 256)\n","        os.makedirs(\"generated_images\", exist_ok=True)\n","        image_path = f\"generated_images/epoch_{epoch}.png\"\n","        # Save image with correct size\n","        utils.save_image(fake_img, image_path, normalize=True)\n","\n","    generator.train()\n","\n","\n","\n","# Checkpoint and loss validation in the training loop:\n","def train_deepkeygen(generator, critic, source_loader, transform_loader, num_epochs, lr, device):\n","    optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))\n","    optimizer_d = optim.Adam(critic.parameters(), lr=lr, betas=(0.5, 0.9))\n","    lambda_gp = 10\n","    critic_iterations = 5\n","\n","    os.makedirs(\"checkpoints\", exist_ok=True)\n","    start_epoch = load_checkpoint(generator, critic, optimizer_g, optimizer_d)\n","\n","    csv_path = \"metrics.csv\"\n","    if not os.path.exists(csv_path):\n","        with open(csv_path, \"w\", newline=\"\") as file:\n","            writer = csv.writer(file)\n","            writer.writerow([\"Epoch\", \"Generator Loss\", \"Critic Loss\", \"Wasserstein Distance\", \"Gradient Penalty\", \"D_real\", \"D_fake\"])\n","\n","    for epoch in range(start_epoch, num_epochs):\n","        print(f\"Epoch : {epoch+1}/{num_epochs}\", flush=True)\n","\n","        for (source_imgs, _), (transform_imgs, _) in zip(source_loader, transform_loader):\n","\n","            min_batch_size = min(source_imgs.size(0), transform_imgs.size(0))\n","            source_imgs = source_imgs[:min_batch_size].to(device)\n","            transform_imgs = transform_imgs[:min_batch_size].to(device)\n","\n","            for _ in range(critic_iterations):\n","                with torch.no_grad():  # Prevent gradient tracking\n","                    z = torch.randn(min_batch_size, 100, 1, 1, device=device)\n","                    fake_imgs = generator(z).detach()  # No gradient needed here\n","\n","                real_loss = critic(transform_imgs).mean()\n","                fake_loss = critic(fake_imgs).mean()\n","                gp = compute_gradient_penalty(critic, transform_imgs, fake_imgs, device)\n","                critic_loss = fake_loss - real_loss + lambda_gp * gp\n","\n","                optimizer_d.zero_grad()\n","                if torch.isnan(critic_loss) or torch.isinf(critic_loss):\n","                    continue\n","                critic_loss.backward()\n","                xm.optimizer_step(optimizer_d)\n","                xm.mark_step()\n","\n","            z = torch.randn(min_batch_size, 100, 1, 1, device=device)\n","            fake_imgs = generator(z)\n","            generator_loss = -critic(fake_imgs).mean()\n","\n","            optimizer_g.zero_grad()\n","            if torch.isnan(generator_loss) or torch.isinf(generator_loss):\n","                continue\n","            generator_loss.backward()\n","            xm.optimizer_step(optimizer_g)\n","            xm.mark_step()\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss D: {critic_loss.item()}, Loss G: {generator_loss.item()}\", flush=True)\n","\n","        wasserstein_distance = real_loss.item() - fake_loss.item()\n","\n","        with open(csv_path, \"a\", newline=\"\") as file:\n","            writer = csv.writer(file)\n","            writer.writerow([epoch+1, generator_loss.item(), critic_loss.item(), wasserstein_distance, gp.item(), real_loss.item(), fake_loss.item()])\n","\n","        save_generated_images(generator, epoch + 1, device)\n","        if (epoch + 1) % 5 == 0:\n","            save_checkpoint(generator, critic, optimizer_g, optimizer_d, epoch)\n","\n","    print(\"[+] Training ended\", flush=True)\n","\n","# Main script\n","if __name__ == \"__main__\":\n","    print(f\"[+] Current working directory: {os.getcwd()}\")\n","\n","    device = xm.xla_device()  # Use TPU device\n","    #device = torch.device(\"cuda\")\n","    print(f\"[+] Using device: {device}\")\n","\n","    #csvpath = \"/content/loss.csv\"\n","\n","    source_datasets = [\"raddar/tuberculosis-chest-xrays-montgomery\", \"masoudnickparvar/brain-tumor-mri-dataset\"]\n","    source_data_dirs = download_datasets(source_datasets)\n","\n","\n","    print(\"[+] Datasets downloaded successfully\")\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((256, 256)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))\n","    ])\n","\n","    batch_size = 32\n","    num_epochs = 100\n","    lr = 0.0002\n","    extract_path = \"/content/transformation\"\n","\n","    source_loader = load_multiple_datasets(source_data_dirs, transform, batch_size)\n","    transform_loader = DataLoader(datasets.ImageFolder(extract_path, transform=transform), batch_size=batch_size, shuffle=True)\n","\n","    print(\"[+] Datasets loaded successfully\")\n","\n","    generator = Generator().to(device)\n","    critic = Critic().to(device)\n","\n","    print(\"[+] Training begins\")\n","    train_deepkeygen(generator, critic, source_loader, transform_loader, num_epochs, lr, device)\n","    print(\"[+] Training ended\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":567},"id":"moUvpPOpLl9K","outputId":"1affaa27-6c7c-4668-e581-f12a25c5b80d","executionInfo":{"status":"error","timestamp":1741081945736,"user_tz":-330,"elapsed":49956,"user":{"displayName":"Kalai Dharun","userId":"03087325867341907797"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[+] Current working directory: /content\n","[+] Using device: xla:0\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/raddar/tuberculosis-chest-xrays-montgomery?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 585M/585M [00:03<00:00, 190MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/masoudnickparvar/brain-tumor-mri-dataset?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 149M/149M [00:00<00:00, 264MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-ec98f380f674>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0msource_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"raddar/tuberculosis-chest-xrays-montgomery\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"masoudnickparvar/brain-tumor-mri-dataset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0msource_data_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-ec98f380f674>\u001b[0m in \u001b[0;36mdownload_datasets\u001b[0;34m(dataset_list)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Function to download multiple datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdataset_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset_dirs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-ec98f380f674>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Function to download multiple datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdataset_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset_dirs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/datasets.py\u001b[0m in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dataset_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Dataset: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompetition\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbased\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0m_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Delete the archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_extract_archive\u001b[0;34m(archive_path, out_path)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Unsupported archive type.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_READ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             self._eof = (self._decompressor.eof or\n\u001b[1;32m   1044\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"4cY7S_xyh9tV"}},{"cell_type":"code","source":["from google.colab import files\n","\n","files.download(\"/content/checkpoints/deepkeygen_checkpoint.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"eu8uAJAYaRCw","executionInfo":{"status":"ok","timestamp":1740911491617,"user_tz":-330,"elapsed":28,"user":{"displayName":"Malarvannan","userId":"10801199715618400703"}},"outputId":"2b7e0697-280a-4c36-9810-0f9ffba0de4d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_baf0d60e-6b6c-428c-9aa4-d056f5722463\", \"deepkeygen_checkpoint.pth\", 45071078)"]},"metadata":{}}]},{"source":["!pip uninstall -y torch torch-xla\n","!pip install torch==2.0.1 --index-url https://download.pytorch.org/whl/cu118\n","!pip install cloud-tpu-client==0.10 torch_xla==2.0.1 --index-url https://download.pytorch.org/whl/cu118"],"cell_type":"code","metadata":{"id":"mx4UwwRbp0OG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"eYsQTe4xkam5"}},{"cell_type":"code","source":["!pip uninstall -y torch torchvision\n","!pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":971},"id":"DNOHwELHka87","executionInfo":{"status":"ok","timestamp":1741048543133,"user_tz":-330,"elapsed":174153,"user":{"displayName":"KISHORE reigns","userId":"05118561739814802865"}},"outputId":"b11d15da-df03-48ba-e35e-fa35ee012137"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.5.1+cpu\n","Uninstalling torch-2.5.1+cpu:\n","  Successfully uninstalled torch-2.5.1+cpu\n","Found existing installation: torchvision 0.20.1+cpu\n","Uninstalling torchvision-0.20.1+cpu:\n","  Successfully uninstalled torchvision-0.20.1+cpu\n","Looking in indexes: https://download.pytorch.org/whl/cu118\n","Collecting torch==2.0.1\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.15.2\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.17.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.5)\n","Collecting triton==2.0.0 (from torch==2.0.1)\n","  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.1.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.1)\n","  Downloading https://download.pytorch.org/whl/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lit (from triton==2.0.0->torch==2.0.1)\n","  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.1.31)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89991 sha256=ea432d1336b6a380b8947f2c5a773ef84a731594a5754ca19bea4bc17811c9ce\n","  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n","Successfully built lit\n","Installing collected packages: lit, cmake, triton, torch, torchvision\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.25.0 lit-15.0.7 torch-2.0.1+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch","torchgen"]},"id":"787bfa170ce24ce0b385b9d3ab689581"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install --upgrade torch torchvision torchaudio\n"],"metadata":{"id":"WNdq5Q1Fozvp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741046760886,"user_tz":-330,"elapsed":7150,"user":{"displayName":"KISHORE reigns","userId":"05118561739814802865"}},"outputId":"97d24e2a-c3cd-498a-8e6c-62d970cc02c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n","Collecting torchvision\n","  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Collecting torchaudio\n","  Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torchvision, torchaudio\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.20.1+cu124\n","    Uninstalling torchvision-0.20.1+cu124:\n","      Successfully uninstalled torchvision-0.20.1+cu124\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.5.1+cu124\n","    Uninstalling torchaudio-2.5.1+cu124:\n","      Successfully uninstalled torchaudio-2.5.1+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torchaudio-2.6.0 torchvision-0.21.0\n"]}]},{"cell_type":"code","source":["!pip uninstall torch torch-xla\n","!pip install torch\n","!pip install torch-xla"],"metadata":{"id":"HTt_KiIRvRUA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","device = xm.xla_device() if 'xm' in globals() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define the Generator model with the same structure as the one used to save the checkpoint\n","import torch\n","\n","device = xm.xla_device() if 'xm' in globals() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define the Generator model with the same structure as the one used to save the checkpoint\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.model = nn.Sequential( # Change 'main' to 'model'\n","            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False), # Adjust output channels to 32 to match the checkpoint\n","            nn.BatchNorm2d(32), # Add BatchNorm2d layer\n","            nn.ReLU(True), # Add ReLU layer\n","            nn.ConvTranspose2d(32, 16, 4, 2, 1, bias=False),  # (16, 128, 128)\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(16, 3, 4, 2, 1, bias=False),  # (3, 256, 256)\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        return self.model(input) # Change 'main' to 'model'\n","\n","\n","\n","\n","\n","generator = Generator().to(device)\n","\n","\n","checkpoint_path = \"/content/drive/MyDrive/Sem6/CIP_Team6_2025/Final_Training/deepkeygen_checkpoint__30-35__epoch.pth\"\n","checkpoint = torch.load(checkpoint_path, map_location=device)\n","generator.load_state_dict(checkpoint[\"generator_state_dict\"])\n","generator.eval()  # Switch to evaluation mode\n","\n","print(\"Model loaded successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"u4KBvOUjagFd","executionInfo":{"status":"error","timestamp":1741048715136,"user_tz":-330,"elapsed":17870,"user":{"displayName":"KISHORE reigns","userId":"05118561739814802865"}},"outputId":"53d5fb18-da90-44f4-946e-90ab79580a8a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"Can't get attribute '_rebuild_device_tensor_from_cpu_tensor' on <module 'torch._utils' from '/usr/local/lib/python3.11/dist-packages/torch/_utils.py'>","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d80fcd7ccafb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Sem6/CIP_Team6_2025/Final_Training/deepkeygen_checkpoint__30-35__epoch.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generator_state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Switch to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1163\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_rebuild_device_tensor_from_cpu_tensor' on <module 'torch._utils' from '/usr/local/lib/python3.11/dist-packages/torch/_utils.py'>"]}]},{"cell_type":"code","source":["import torch\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import torchvision.transforms as transforms\n","\n","# Load the medical image\n","image_path = \"/content/drive/MyDrive/Sem6/CIP_Team6_2025/Medical_Images/MCUCXR_0001_0.png\"\n","image = Image.open(image_path).convert(\"L\")\n","\n","# Define image transformations\n","transform = transforms.Compose([\n","    transforms.Resize((256,256)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])\n","])\n","\n","# Apply transformations\n","image_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n","\n","z = torch.randn(1, 100, 1, 1, device=device)\n","\n","# Reshape the noise vector to have the same spatial dimensions as the image tensor\n","z = z.repeat(1, 1, image_tensor.shape[2], image_tensor.shape[3]) # Repeat z along spatial dimensions\n","\n","# Instead of concatenating, only use the noise vector 'z' as input to the generator:\n","# with torch.no_grad():\n","#     fake_image = generator(z)\n","\n","# Pass only the noise vector (z) to the generator\n","with torch.no_grad():\n","    fake_image = generator(z)\n","\n","\n","os.makedirs(\"generated_images\", exist_ok=True)\n","image_path = \"generated_images/generated_sample.png\"\n","# Make sure utils is imported from torchvision\n","from torchvision import utils\n","utils.save_image(fake_image, image_path, normalize=True)\n","\n","print(f\"Generated image saved at: {image_path}\")"],"metadata":{"id":"ZlQV5ZT2WOF6","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"error","timestamp":1741048203260,"user_tz":-330,"elapsed":10177,"user":{"displayName":"KISHORE reigns","userId":"05118561739814802865"}},"outputId":"c8b22273-75c7-4042-bfa5-34a6e1bf0b7d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-05a551a642ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"source":["!pip uninstall -y torch torchvision\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-gXnEphRegxH","executionInfo":{"status":"ok","timestamp":1741047078876,"user_tz":-330,"elapsed":264245,"user":{"displayName":"KISHORE reigns","userId":"05118561739814802865"}},"outputId":"e8e0fc16-c374-4fc1-add4-772bea4b6afc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.6.0\n","Uninstalling torch-2.6.0:\n","  Successfully uninstalled torch-2.6.0\n","Found existing installation: torchvision 0.21.0\n","Uninstalling torchvision-0.21.0:\n","  Successfully uninstalled torchvision-0.21.0\n","\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu118\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118 torchvision-0.21.0+cu118\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch","torchgen"]},"id":"db8a268e3528436c8341e220064a81e3"}},"metadata":{}}]}]}